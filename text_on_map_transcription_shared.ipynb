{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_on_map_transcription_shared.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffblackadar/crane-pompeii/blob/master/text_on_map_transcription_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxxHIASLKrkX"
      },
      "source": [
        "This notebook uses Azure Cognitive Services to transcribe text on an old map.\r\n",
        "It then puts the text with its geographic location into a shapefile.\r\n",
        "A blog post about it is here: http://jeffblackadar.ca/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAinl_xpRhx7"
      },
      "source": [
        "# https://towardsdatascience.com/mapping-with-matplotlib-pandas-geopandas-and-basemap-in-python-d11b57ab5dac\r\n",
        "# https://stackoverflow.com/questions/54613992/how-to-install-and-use-basemap-on-google-colab\r\n",
        "# !apt-get install libgeos-3.6.2 (I am not sure if this is needed)\r\n",
        "!apt-get install libgeos-dev\r\n",
        "!pip install https://github.com/matplotlib/basemap/archive/master.zip\r\n",
        "!pip install geopandas\r\n",
        "!pip install contextily\r\n",
        "!pip install -U rasterio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdD4oJj3RlZH"
      },
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4YdvPXFfbwp"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E45bxJrpGQI2"
      },
      "source": [
        "settings_path = \"/content/drive/MyDrive/william_white/\"\r\n",
        "    \r\n",
        "import os\r\n",
        "import json\r\n",
        "# Set the file we wan!pip install --upgrade azure-cognitiveservices-vision-computervisiont to use for authenticating an Azure app\r\n",
        "# The json file stores the COMPUTER_VISION_SUBSCRIPTION_KEY and COMPUTER_VISION_ENDPOINT so we don't have it in the code.\r\n",
        "# The json file looks like this:\r\n",
        "# {\r\n",
        "# \"COMPUTER_VISION_SUBSCRIPTION_KEY\":\"___the_COMPUTER_VISION_SUBSCRIPTION_KEY___\",\r\n",
        "# \"COMPUTER_VISION_ENDPOINT\":\"___the_COMPUTER_VISION_ENDPOINT___\"\r\n",
        "# }\r\n",
        "# cv.json contains the credentials for this program.\r\n",
        "cv_settings_file = settings_path+'cv.json'\r\n",
        "with open(cv_settings_file, \"r\") as read_file:\r\n",
        "    cv_auth_data = json.load(read_file)\r\n",
        "\r\n",
        "os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']=cv_auth_data[\"COMPUTER_VISION_SUBSCRIPTION_KEY\"]\r\n",
        "os.environ['COMPUTER_VISION_ENDPOINT']=cv_auth_data[\"COMPUTER_VISION_ENDPOINT\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiMhMG-Dz4mP"
      },
      "source": [
        "# https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/python-sdk\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-XeDxx309x"
      },
      "source": [
        "# Add your Computer Vision subscription key to your environment variables.\n",
        "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
        "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
        "else:\n",
        "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
        "    sys.exit()\n",
        "# Add your Computer Vision endpoint to your environment variables.\n",
        "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
        "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
        "else:\n",
        "    print(\"\\nSet the COMPUTER_VISION_ENDPOINT environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
        "    sys.exit()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7RmGZkWBsUU"
      },
      "source": [
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTEQR5cVKo9g"
      },
      "source": [
        "'''\n",
        "Batch Read File, recognize printed text - remote\n",
        "This example will extract printed text in an image, then print results, line by line.\n",
        "This API call can also recognize handwriting (not shown).\n",
        "'''\n",
        "print(\"===== Batch Read File - remote =====\")\n",
        "# Get an image with printed text\n",
        "remote_image_handw_text_url = \"http://jeffblackadar.ca/charcoal_hearths/UnionTshp_1876%20clip_georef.tif\"\n",
        "\n",
        "# Call API with URL and raw response (allows you to get the operation location)\n",
        "recognize_handw_results = computervision_client.read(remote_image_handw_text_url,  raw=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihzgPr1Ydguj"
      },
      "source": [
        "# Get the operation location (URL with an ID at the end) from the response\r\n",
        "operation_location_remote = recognize_handw_results.headers[\"Operation-Location\"]\r\n",
        "# Grab the ID from the URL\r\n",
        "operation_id = operation_location_remote.split(\"/\")[-1]\r\n",
        "\r\n",
        "# Call the \"GET\" API and wait for it to retrieve the results \r\n",
        "while True:\r\n",
        "    get_handw_text_results = computervision_client.get_read_result(operation_id)\r\n",
        "    if get_handw_text_results.status not in ['notStarted', 'running']:\r\n",
        "        break\r\n",
        "    time.sleep(1)\r\n",
        "\r\n",
        "# Print the detected text, line by line\r\n",
        "lines_of_text = []\r\n",
        "if get_handw_text_results.status == OperationStatusCodes.succeeded:\r\n",
        "    for text_result in get_handw_text_results.analyze_result.read_results:\r\n",
        "        for line in text_result.lines:\r\n",
        "            line_data = []  \r\n",
        "            print(line.text)\r\n",
        "            line_data.append(line.text)\r\n",
        "            # print(line.bounding_box)\r\n",
        "            line_data.append(line.bounding_box)\r\n",
        "            lines_of_text.append(line_data)\r\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX8Bb6LYLHVB"
      },
      "source": [
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import gdal\r\n",
        "import geopandas as gpd\r\n",
        "from shapely.geometry import Point, Polygon\r\n",
        "\r\n",
        "font                   = cv2.FONT_HERSHEY_SIMPLEX\r\n",
        "bottomLeftCornerOfText = (10,500)\r\n",
        "fontScale              = 1\r\n",
        "fontColor              = (0,0,200)\r\n",
        "lineType               = 2\r\n",
        "\r\n",
        "# read the image\r\n",
        "img = cv2.imread(\"/content/drive/MyDrive/MaskCNNhearths/HopewellFurnace/UnionTshp_1876 clip_georef.tif\",-1)\r\n",
        "img_ds = gdal.Open(\"/content/drive/MyDrive/MaskCNNhearths/HopewellFurnace/UnionTshp_1876 clip_georef.tif\") \r\n",
        "\r\n",
        "#GeoTransform[0] /* top left x */\r\n",
        "#GeoTransform[1] /* w-e pixel resolution */\r\n",
        "#GeoTransform[2] /* 0 */\r\n",
        "#GeoTransform[3] /* top left y */\r\n",
        "#GeoTransform[4] /* 0 */\r\n",
        "#GeoTransform[5] /* n-s pixel resolution (negative value) */\r\n",
        "\r\n",
        "xoffset, px_w, rot1, yoffset, rot2, px_h  = img_ds.GetGeoTransform()\r\n",
        "\r\n",
        "line_text_poly = gpd.GeoDataFrame()\r\n",
        "line_text_poly['geometry'] = None\r\n",
        "geotif_crs = 32129\r\n",
        "line_text_poly.crs = (\"EPSG:\" + str(geotif_crs))\r\n",
        "line_text_poly.geometry = line_text_poly.geometry.to_crs(crs=geotif_crs)\r\n",
        "line_text_poly.to_crs(crs=geotif_crs)\r\n",
        "line_text_poly = line_text_poly.to_crs(epsg=geotif_crs)\r\n",
        "\r\n",
        "# thanks to https://stackoverflow.com/questions/50191648/gis-geotiff-gdal-python-how-to-get-coordinates-from-pixel\r\n",
        "def get_point_from_pixel(x,y, xoffset, px_w, rot1, yoffset, px_h, rot2):\r\n",
        "    # supposing x and y are your pixel coordinate this \r\n",
        "    # is how to get the coordinate in space.\r\n",
        "    posX = px_w * x + rot1 * y + xoffset\r\n",
        "    posY = rot2 * x + px_h * y + yoffset\r\n",
        "\r\n",
        "    posX = (px_w * x) + (rot1 * y) + xoffset\r\n",
        "    posY = (px_h * y) + (rot2 * x) + yoffset\r\n",
        "    # shift to the center of the pixel\r\n",
        "    posX += px_w / 2.0\r\n",
        "    posY += px_h / 2.0\r\n",
        "    return(posX,posY)\r\n",
        "    \r\n",
        "ln = 0\r\n",
        "for l in lines_of_text:\r\n",
        "    pts = l[1]\r\n",
        "    # add text\r\n",
        "    cv2.putText(img, l[0], (int(pts[0]),int(pts[1])),  font,  fontScale,  fontColor, lineType)\r\n",
        "    # add rectangle\r\n",
        "    cv2.rectangle(img,(int(pts[0]),int(pts[1])),(int(pts[4]),int(pts[5])),fontColor)\r\n",
        "  \r\n",
        "    p=[]\r\n",
        "    for cn in range(0,4):\r\n",
        "        p.append(get_point_from_pixel(pts[0+(cn*2)],pts[1+(cn*2)], xoffset, px_w, rot1, yoffset, px_h, rot2))\r\n",
        "    coords = [(p[0][0], p[0][1]), (p[1][0], p[1][1]), (p[2][0], p[2][1]), (p[3][0], p[3][1])]\r\n",
        "    \r\n",
        "    poly = Polygon(coords)\r\n",
        "    new_tp_row = {'id':ln, 'geometry':poly,'text':l[0]}\r\n",
        "    line_text_poly = line_text_poly.append(new_tp_row, ignore_index=True)\r\n",
        "    \r\n",
        "line_text_poly.to_file(\"line_text.shp\")\r\n",
        "from matplotlib.pyplot import figure\r\n",
        "figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\r\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iq8T4cgRrNo"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.basemap import Basemap\r\n",
        "import geopandas as gpd\r\n",
        "import pandas as pd\r\n",
        "import contextily as ctx"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeBgEwhLRu8L"
      },
      "source": [
        "line_text_df=gpd.read_file(\"/content/line_text.shp\")\r\n",
        "\r\n",
        "print(line_text_df.crs)\r\n",
        "# Change crs to one compatible with basemap\r\n",
        "line_text_df = line_text_df.to_crs(epsg=3857) #3857\r\n",
        "print(line_text_df.crs)\r\n",
        "\r\n",
        "ax = line_text_df.plot(figsize=(20, 20), alpha=0.2, edgecolor='k')\r\n",
        "ctx.add_basemap(ax)\r\n",
        "\r\n",
        "line_text_df['coords'] = line_text_df['geometry'].apply(lambda x: x.representative_point().coords[:])\r\n",
        "line_text_df['coords'] = [coords[0] for coords in line_text_df['coords']]\r\n",
        "for idx, row in line_text_df.iterrows():\r\n",
        "    plt.annotate(s=row['text'], xy=row['coords'],\r\n",
        "                 horizontalalignment='center')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgW1JQQ2KId7"
      },
      "source": [
        "Download /content/line_text.shp to use it in other maps such as ArcGIS Map. "
      ]
    }
  ]
}