{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program connects to Box.com, gets all of the folders and images and stores information into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.box.com/en/guides/authentication/oauth2/with-sdk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boxsdk\n",
      "  Using cached boxsdk-2.7.1-py2.py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: wrapt>=1.10.1 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from boxsdk) (1.11.2)\n",
      "Collecting requests-toolbelt<1.0.0,>=0.4.0\n",
      "  Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from boxsdk) (1.14.0)\n",
      "Collecting requests>=2.4.3\n",
      "  Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from boxsdk) (19.3.0)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.4.3->boxsdk) (2019.11.28)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5\n",
      "  Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "Installing collected packages: chardet, urllib3, idna, requests, requests-toolbelt, boxsdk\n",
      "Successfully installed boxsdk-2.7.1 chardet-3.0.4 idna-2.8 requests-2.22.0 requests-toolbelt-0.9.1 urllib3-1.25.8\n",
      "Collecting auth\n",
      "  Using cached auth-0.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting falcon\n",
      "  Downloading falcon-2.0.0-cp36-cp36m-manylinux1_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 3.5 MB/s eta 0:00:01     |█████████████████▋              | 2.5 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from auth) (0.16.1)\n",
      "Collecting eventlet\n",
      "  Using cached eventlet-0.25.1-py2.py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: requests in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from auth) (2.22.0)\n",
      "Collecting gunicorn\n",
      "  Using cached gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting mongoengine\n",
      "  Using cached mongoengine-0.19.1.tar.gz (157 kB)\n",
      "Collecting blinker\n",
      "  Using cached blinker-1.4.tar.gz (111 kB)\n",
      "Collecting greenlet>=0.3\n",
      "  Downloading greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 274 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dnspython>=1.15.0\n",
      "  Using cached dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from eventlet->auth) (1.14.0)\n",
      "Collecting monotonic>=1.4\n",
      "  Using cached monotonic-1.5-py2.py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests->auth) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests->auth) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests->auth) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests->auth) (2.8)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from gunicorn->auth) (45.1.0.post20200127)\n",
      "Collecting pymongo>=3.4\n",
      "  Downloading pymongo-3.10.1-cp36-cp36m-manylinux2014_x86_64.whl (460 kB)\n",
      "\u001b[K     |████████████████████████████████| 460 kB 41.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: mongoengine, blinker\n",
      "  Building wheel for mongoengine (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mongoengine: filename=mongoengine-0.19.1-py3-none-any.whl size=108302 sha256=e7623261cf79cb5d2b547398e9cc00055127819deed975b9d741778d8f6d6061\n",
      "  Stored in directory: /home/student/.cache/pip/wheels/c1/e8/5c/46757b14f42eb3bf2a19c022d3efa72c5b9ef19c9660211c31\n",
      "  Building wheel for blinker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13451 sha256=597f66ce416b7becd54a40b5b14502cc968f80677357561f582c766bf6b16a0b\n",
      "  Stored in directory: /home/student/.cache/pip/wheels/4f/4a/93/c5ed8c11fedbe97fb8b8032b301eaa736248684b44087a7259\n",
      "Successfully built mongoengine blinker\n",
      "Installing collected packages: falcon, greenlet, dnspython, monotonic, eventlet, gunicorn, pymongo, mongoengine, blinker, auth\n",
      "Successfully installed auth-0.5.3 blinker-1.4 dnspython-1.16.0 eventlet-0.25.1 falcon-2.0.0 greenlet-0.4.15 gunicorn-20.0.4 mongoengine-0.19.1 monotonic-1.5 pymongo-3.10.1\n",
      "Collecting redis\n",
      "  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-3.4.1\n",
      "Collecting mysql.connector\n",
      "  Using cached mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
      "Building wheels for collected packages: mysql.connector\n",
      "  Building wheel for mysql.connector (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mysql.connector: filename=mysql_connector-2.2.9-cp36-cp36m-linux_x86_64.whl size=247950 sha256=96def7494d9d933034959e434b7e97c7f5d87929fc77b7136ce01aca78102010\n",
      "  Stored in directory: /home/student/.cache/pip/wheels/23/27/3e/72be437e6a950b8972728d2a62935ae7cd0d7c3c251fb2e737\n",
      "Successfully built mysql.connector\n",
      "Installing collected packages: mysql.connector\n",
      "Successfully installed mysql.connector\n",
      "Requirement already satisfied: requests in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from requests) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install boxsdk\n",
    "!pip install auth\n",
    "!pip install redis\n",
    "!pip install mysql.connector\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the cell below to authenticate with Box.com so we can use the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rvy5o5ic72c00ldi8vpcqmof0t7h6w85\n",
      "VWJQ1LTracitLw5HfG8Q0TKplBogFEIT\n",
      "Click on this:\n",
      "https://account.box.com/api/oauth2/authorize?state=box_csrf_token_bMTNEZACGRXj20bK&response_type=code&client_id=rvy5o5ic72c00ldi8vpcqmof0t7h6w85&redirect_uri=https%3A%2F%2Fjeffblackadar.ca\n",
      "box_csrf_token_bMTNEZACGRXj20bK\n",
      "Copy the code that follows code= in the URL.  Paste it into the oauth.authenticate('___the_code___') below.  Be quick, the code lasts only a few seconds.\n"
     ]
    }
   ],
   "source": [
    "from boxsdk import OAuth2\n",
    "\n",
    "import json\n",
    "#Set the file we want to use for authenticating a Box app\n",
    "#The json file stores the client_id and client_secret so we don't have it in the code.\n",
    "# The json file looks like this:\n",
    "#{\n",
    "#\"client_id\":\"___the_codes_for_client_id___\",\n",
    "#\"client_secret\":\"___the_codes_for_client_secret___\"\n",
    "#}\n",
    "\n",
    "oauth_settings_file = '/home/student/jeff_not_data_5000/programs/box_app_test.json'\n",
    "with open(oauth_settings_file, \"r\") as read_file:\n",
    "    oauth_data = json.load(read_file)\n",
    "print(oauth_data[\"client_id\"])\n",
    "print(oauth_data[\"client_secret\"])\n",
    "\n",
    "oauth = OAuth2(\n",
    "    client_id=oauth_data[\"client_id\"],\n",
    "    client_secret=oauth_data[\"client_secret\"]\n",
    ")\n",
    "\n",
    "auth_url, csrf_token = oauth.get_authorization_url('https://jeffblackadar.ca')\n",
    "print(\"Click on this:\")\n",
    "print(auth_url)\n",
    "print(csrf_token)\n",
    "print(\"Copy the code that follows code= in the URL.  Paste it into the oauth.authenticate('___the_code___') below.  Be quick, the code lasts only a few seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boxsdk import Client\n",
    "\n",
    "# Make sure that the csrf token you get from the `state` parameter\n",
    "# in the final redirect URI is the same token you get from the\n",
    "# get_authorization_url method to protect against CSRF vulnerabilities.\n",
    "#assert 'THE_CSRF_TOKEN_YOU_GOT' == csrf_token\n",
    "access_token, refresh_token = oauth.authenticate('aubN94nFeXUNNO6zncOwqkUBHUi5Vv6U')\n",
    "client = Client(oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the connection to Box.com - list all folders and files using recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subfolder_test(client, folder_id, folder_name):\n",
    "    print(\"this folder: \"+folder_name)\n",
    "    items = client.folder(folder_id=folder_id).get_items()\n",
    "    for item in items:\n",
    "        print('{0} {1} is named \"{2}\"'.format(item.type.capitalize(), item.id, item.name))\n",
    "        if(item.type.capitalize()==\"Folder\"):\n",
    "            process_subfolder_test(client, item.id,folder_name+\"/\"+item.name)\n",
    "        if(item.type.capitalize()==\"File\"):\n",
    "            #print(item)\n",
    "            print('File: {0} is named: \"{1}\" path: {2} '.format(item.id, item.name, folder_name+\"/\"+item.name))            \n",
    "    return\n",
    "\n",
    "process_subfolder_test(client, '0',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start MySQL\n",
    "\n",
    "sudo systemctl start mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all folders and store all files into a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subfolder(client, folder_id, folder_name,cursor_insert):\n",
    "    print(\"this folder: \"+folder_name)\n",
    "    items = client.folder(folder_id=folder_id).get_items()\n",
    "    for item in items:\n",
    "        print('{0} {1} is named \"{2}\"'.format(item.type.capitalize(), item.id, item.name))\n",
    "        if(item.type.capitalize()==\"Folder\"):\n",
    "            process_subfolder(client, item.id,folder_name+\"/\"+item.name,cursor_insert)\n",
    "        if(item.type.capitalize()==\"File\"):\n",
    "            #print(item)\n",
    "            print('File: {0} is named: \"{1}\" path: {2} '.format(item.id, item.name, folder_name+\"/\"+item.name))\n",
    "            \n",
    "            insert_image = (\"INSERT INTO tbl_box_images (`id_box_file`,`id_box_folder`,`folder`,`file_name`,`img_src`,`img_url`) VALUES (%s,%s,%s,%s,%s,%s);\")\n",
    "            \n",
    "            cursor_insert.execute(insert_image, (item.id, folder_id, folder_name, item.name, folder_name+\"/\"+item.name, \"\"))\n",
    "            mariadb_connection.commit()\n",
    "    return\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "base_dir = 'C:\\\\a_orgs\\\\carleton\\\\hist3814\\\\R\\\\pompeii\\\\box'\n",
    "\n",
    "\n",
    "import mysql.connector as mariadb\n",
    "\n",
    "mariadb_connection = mariadb.connect(option_files='C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\webpage_images.cnf', option_groups=\"webpage_images\")\n",
    "\n",
    "cursor_insert = mariadb_connection.cursor(buffered=True)\n",
    "\n",
    "process_subfolder(client, '0',\"\", cursor_insert)\n",
    "    \n",
    "mariadb_connection.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mariadb_connection.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process images: Connect to Box.com, download image, get its hash value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.3.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25853 sha256=60a616b9e2cabad44117bf93922a209f14a7f5a84c2998c601ce231cfe3d5d4c\n",
      "  Stored in directory: /home/student/.cache/pip/wheels/27/4d/3a/6dcdf7c3ebc87bf1ae013d96c9cf060ccfe334bb5ee769f377\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    " !pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image hash functions\n",
    "# import the necessary packages\n",
    "# Credit Adrian Rosebrock https://www.pyimagesearch.com\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# hashing with OpenCV and PythonPython\n",
    "def dhash(image, hashSize=8):\n",
    "    # resize the input image, adding a single column (width) so we\n",
    "    # can compute the horizontal gradient\n",
    "    resized = cv2.resize(image, (hashSize + 1, hashSize))\n",
    "\n",
    "    # compute the (relative) horizontal gradient between adjacent\n",
    "    # column pixels\n",
    "    diff = resized[:, 1:] > resized[:, :-1]\n",
    "\n",
    "    # convert the difference image to a hash\n",
    "    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cursor_update' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cfbd86959051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdownload_process_box_thumbnail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3063\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"580416299144\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/pinp5/Maps/Maps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Plan Bay of Naples 1865 from Karl von Spruner’s 1865 rendering of Southern Italy and Sicily in antiquity Wikimedia.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cursor_update' is not defined"
     ]
    }
   ],
   "source": [
    "download_process_box_thumbnail(client,3063, \"580416299144\", \"/pinp5/Maps/Maps\", \"Plan Bay of Naples 1865 from Karl von Spruner’s 1865 rendering of Southern Italy and Sicily in antiquity Wikimedia.jpg\", cursor_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "base_dir = '/home/student/jeff_not_data_5000/images/box/'\n",
    "\n",
    "# using the thumbnail for image hashing does not work   \n",
    "def download_process_box_full_id_box_file(client, id_box, id_box_file, folder, file_name, cursor_update):\n",
    "    #Some file names can't be processed.  This uses the box file name instead.\n",
    "    print(\"this file: \"+id_box_file+\" \"+file_name)\n",
    "    #using the the large 320 pixel thumbnail produces different results than the full image - it does not work\n",
    "    #try:\n",
    "    #file_info = client.file(id_box_file).get()\n",
    "    file_name = id_box_file+\".jpg\"\n",
    "    imagecontent = client.file(id_box_file).content()\n",
    "    # load the image for the image hash later.\n",
    "\n",
    "    img_local_path=base_dir+folder+\"/\"+file_name\n",
    "    #print(img_local_path)\n",
    "    img_file_name = file_name\n",
    "    img_local_folder = base_dir+folder\n",
    "\n",
    "    #see if the image is there already\n",
    "    if not os.path.exists(img_local_path):\n",
    "        img_file_name = file_name\n",
    "        img_local_folder = base_dir+folder\n",
    "        \n",
    "        if not os.path.exists(img_local_folder):\n",
    "            #os.mkdir(img_local_folder)\n",
    "            path = Path(img_local_folder)\n",
    "            path.mkdir(parents=True,exist_ok=True)\n",
    "            #print(img_local_folder+'/'+ img_file_name)\n",
    "            \n",
    "            # Open the url image, set stream to True, this will return the stream content.\n",
    "            # Open a local file with wb ( write binary ) permission.\n",
    "            #local_file = open(img_local_folder+'/'+ img_file_name, 'wb')\n",
    "        with open(img_local_folder+'/'+ img_file_name,'wb') as f:\n",
    "                f.write(imagecontent)\n",
    "            #print(thumbnail)\n",
    "        del imagecontent\n",
    "        f.close()\n",
    "            #image hash\n",
    "    imageHash = 0\n",
    "    #print(\"image hash\")\n",
    "    if not os.path.exists(img_local_path):\n",
    "        print(\"Error image not loaded for image hash   \" + img_local_path)\n",
    "    else:         \n",
    "        # load the image from disk\n",
    "        path = Path(img_local_folder)\n",
    "        os.chdir(path)\n",
    "        hash_image = cv2.imread(img_file_name)\n",
    " \n",
    "        # if the image is None then we could not load it from disk (so skip it)\n",
    "        if not hash_image is None:\n",
    "            # convert the image to grayscale and compute the hash\n",
    "            hash_image = cv2.cvtColor(hash_image, cv2.COLOR_BGR2GRAY)\n",
    "            imageHash = dhash(hash_image)\n",
    "            #print(imageHash)\n",
    "        else:\n",
    "            imageHash = 0\n",
    "            #print(\"image hash - can't find image?\")\n",
    "        update_image = (\"UPDATE tbl_box_images SET image_hash = %s WHERE id = %s;\")\n",
    "        print(id_box, imageHash)\n",
    "        cursor_update.execute(update_image, (imageHash, id_box))\n",
    "        mariadb_connection.commit()\n",
    "        \n",
    "        \n",
    "        os.remove(img_local_path)\n",
    "    return\n",
    "    #except:\n",
    "    #    print(sys.exc_info()[0])\n",
    "    #    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows_to_run = 100000\n",
    "start_id = 165806\n",
    "end_id = start_id+number_of_rows_to_run\n",
    "\n",
    "import mysql.connector as mariadb\n",
    "mariadb_connection = mariadb.connect(option_files='/home/student/jeff_not_data_5000/programs/webpage_images.cnf', option_groups=\"webpage_images\")\n",
    "cursor = mariadb_connection.cursor(buffered=True)\n",
    "cursor_update = mariadb_connection.cursor(buffered=True)\n",
    "cursor.execute(\"SELECT id, id_box_file, folder, file_name, img_path_match, id_tbl_webpage_images, img_src FROM webpage_images.tbl_box_images WHERE id>=%s AND id<%s\", (start_id, end_id))\n",
    "for id, id_box_file, folder, file_name, img_path_match, id_tbl_webpage_images, img_src in cursor:\n",
    "    #print(id, id_box_file, img_path_match, id_tbl_webpage_images, img_src)\n",
    "    #don't include .xml, .htm* or .thmx\n",
    "    #for row 158348\n",
    "    if(img_path_match is None):\n",
    "        img_path_match = \"\"\n",
    "    if (img_src.lower().find(\".xml\")<0) and (img_src.lower().find(\".htm\")<0) and (img_src.lower().find(\".thmx\")<0) and (img_src.lower().find(\".js\")<0) and (img_src.lower().find(\".pdf\")<0) and (img_src.lower().find(\".zip\")<0) and (img_src.lower().find(\".asp\")<0) and (img_src.lower().find(\".txt\")<0) and (img_src.lower().find(\".ico\")<0):\n",
    "        download_process_box_full_id_box_file(client, id, str(id_box_file), folder, file_name, cursor_update)\n",
    "            \n",
    "cursor.close()\n",
    "cursor_update.close()\n",
    "mariadb_connection.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mariadb_connection.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
